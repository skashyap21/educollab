This folder contains code of binary classification of Text Profanity.

Here's a little description of the files in this folder.

* Model Selection.ipynb - This file contains the code of model comparison.
* Handling Data Imbalance.ipynb - In this file we try to handle the data imbalance in our dataset.
* Model.ipynb - This file contains the code of our final model.

Dataset - We took the dataset from Toxic Comment Classification challenge on kaggle (https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge).